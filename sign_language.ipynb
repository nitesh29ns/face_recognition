{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\ml\\\\yolov5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D:/ml/yolov5/sigin_language/data.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qr requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=./models/custom_yolov5s.yaml, data=./data/data.yaml, hyp=data\\hyps\\hyp.scratch-low.yaml, epochs=300, batch_size=16, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs\\train, name=yolov5s_results, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 \n",
      "YOLOv5  v7.0-107-g7a972e8 Python-3.7.15 torch-1.13.1+cpu CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5  in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5  runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\train', view at http://localhost:6006/\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to C:\\Users\\nites\\AppData\\Roaming\\Ultralytics\\Arial.ttf...\n",
      "\n",
      "  0%|          | 0.00/755k [00:00<?, ?B/s]\n",
      " 12%|█▏        | 88.0k/755k [00:00<00:00, 804kB/s]\n",
      " 31%|███       | 232k/755k [00:00<00:00, 1.08MB/s]\n",
      " 55%|█████▌    | 416k/755k [00:00<00:00, 1.33MB/s]\n",
      " 75%|███████▌  | 568k/755k [00:00<00:00, 1.40MB/s]\n",
      "100%|██████████| 755k/755k [00:00<00:00, 1.42MB/s]\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     29667  models.yolo.Detect                      [6, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "custom_YOLOv5s summary: 214 layers, 7035811 parameters, 7035811 gradients, 16.0 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\ml\\yolov5\\sigin_language\\train\\labels...:   0%|          | 0/120 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\ml\\yolov5\\sigin_language\\train\\labels... 1 images, 0 backgrounds, 0 corrupt:   1%|          | 1/120 [00:10<20:32, 10.36s/it]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\ml\\yolov5\\sigin_language\\train\\labels... 8 images, 0 backgrounds, 0 corrupt:   7%|▋         | 8/120 [00:10<01:47,  1.05it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\ml\\yolov5\\sigin_language\\train\\labels... 17 images, 0 backgrounds, 0 corrupt:  14%|█▍        | 17/120 [00:10<00:37,  2.74it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\ml\\yolov5\\sigin_language\\train\\labels... 39 images, 0 backgrounds, 0 corrupt:  32%|███▎      | 39/120 [00:10<00:09,  8.48it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\ml\\yolov5\\sigin_language\\train\\labels... 86 images, 0 backgrounds, 0 corrupt:  72%|███████▏  | 86/120 [00:10<00:01, 25.24it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\ml\\yolov5\\sigin_language\\train\\labels... 120 images, 0 backgrounds, 0 corrupt: 100%|██████████| 120/120 [00:10<00:00, 11.05it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: D:\\ml\\yolov5\\sigin_language\\train\\labels.cache\n",
      "\n",
      "  0%|          | 0/120 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram):  53%|█████▎    | 64/120 [00:00<00:00, 615.41it/s]\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram): 100%|██████████| 120/120 [00:00<00:00, 714.28it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\ml\\yolov5\\sigin_language\\test\\labels...:   0%|          | 0/30 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\ml\\yolov5\\sigin_language\\test\\labels... 1 images, 0 backgrounds, 0 corrupt:   3%|▎         | 1/30 [00:17<08:19, 17.22s/it]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\ml\\yolov5\\sigin_language\\test\\labels... 4 images, 0 backgrounds, 0 corrupt:  13%|█▎        | 4/30 [00:17<01:25,  3.29s/it]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\ml\\yolov5\\sigin_language\\test\\labels... 10 images, 0 backgrounds, 0 corrupt:  33%|███▎      | 10/30 [00:17<00:20,  1.00s/it]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\ml\\yolov5\\sigin_language\\test\\labels... 16 images, 0 backgrounds, 0 corrupt:  53%|█████▎    | 16/30 [00:17<00:07,  1.95it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\ml\\yolov5\\sigin_language\\test\\labels... 22 images, 0 backgrounds, 0 corrupt:  73%|███████▎  | 22/30 [00:17<00:02,  3.26it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\ml\\yolov5\\sigin_language\\test\\labels... 28 images, 0 backgrounds, 0 corrupt:  93%|█████████▎| 28/30 [00:17<00:00,  5.02it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\ml\\yolov5\\sigin_language\\test\\labels... 30 images, 0 backgrounds, 0 corrupt: 100%|██████████| 30/30 [00:17<00:00,  1.68it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: D:\\ml\\yolov5\\sigin_language\\test\\labels.cache\n",
      "\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100%|██████████| 30/30 [00:00<00:00, 383.15it/s]\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.85 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset \n",
      "Plotting labels to runs\\train\\yolov5s_results\\labels.jpg... \n",
      "Image sizes 416 train, 416 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\train\\yolov5s_results\u001b[0m\n",
      "Starting training for 300 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]\n",
      "  0%|          | 0/8 [00:02<?, ?it/s]\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 640, in <module>\n",
      "    main(opt)\n",
      "  File \"train.py\", line 529, in main\n",
      "    train(opt.hyp, opt, device, callbacks)\n",
      "  File \"train.py\", line 310, in train\n",
      "    pred = model(imgs)  # forward\n",
      "  File \"c:\\Users\\nites\\miniconda3\\envs\\tensrflow\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"d:\\ml\\yolov5\\models\\yolo.py\", line 209, in forward\n",
      "    return self._forward_once(x, profile, visualize)  # single-scale inference, train\n",
      "  File \"d:\\ml\\yolov5\\models\\yolo.py\", line 121, in _forward_once\n",
      "    x = m(x)  # run\n",
      "  File \"c:\\Users\\nites\\miniconda3\\envs\\tensrflow\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"d:\\ml\\yolov5\\models\\common.py\", line 168, in forward\n",
      "    return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), 1))\n",
      "  File \"c:\\Users\\nites\\miniconda3\\envs\\tensrflow\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"c:\\Users\\nites\\miniconda3\\envs\\tensrflow\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 204, in forward\n",
      "    input = module(input)\n",
      "  File \"c:\\Users\\nites\\miniconda3\\envs\\tensrflow\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"d:\\ml\\yolov5\\models\\common.py\", line 121, in forward\n",
      "    return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))\n",
      "  File \"c:\\Users\\nites\\miniconda3\\envs\\tensrflow\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"d:\\ml\\yolov5\\models\\common.py\", line 57, in forward\n",
      "    return self.act(self.bn(self.conv(x)))\n",
      "  File \"c:\\Users\\nites\\miniconda3\\envs\\tensrflow\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1194, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"c:\\Users\\nites\\miniconda3\\envs\\tensrflow\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 463, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"c:\\Users\\nites\\miniconda3\\envs\\tensrflow\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 460, in _conv_forward\n",
      "    self.padding, self.dilation, self.groups)\n",
      "RuntimeError: [enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 22151168 bytes.\n"
     ]
    }
   ],
   "source": [
    "!python train.py --img 416 --batch 16 --epochs 300 --data ./data/data.yaml --cfg ./models/custom_yolov5s.yaml --weights yolov5s.pt --name yolov5s_results  --cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"D:/ml/yolov5/data.yaml\") as file:\n",
    "    contant=file.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train: /train/images\\n',\n",
       " 'val: /test/images\\n',\n",
       " '\\n',\n",
       " 'nc: 6\\n',\n",
       " \"names: ['Hello', 'IloveYou', 'No', 'Please', 'Thanks', 'Yes']\\n\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C:/Users/nites/Documents/data_science/computer_vision/my_photo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\nites\\\\Documents\\\\data_science\\\\computer_vision\\\\my_photo'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"images\",exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"labels\",exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classes.txt', 'IMG_0345.JPG', 'IMG_0345.txt', 'IMG_0347.JPG']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =os.listdir('nitesh')\n",
    "data[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'classes.txt'.endswith('.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[]\n",
    "images=[]\n",
    "for i in data:\n",
    "    if i.endswith('.txt'):\n",
    "        labels.append(i)\n",
    "    else:\n",
    "        images.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['classes.txt',\n",
       " 'IMG_0345.txt',\n",
       " 'IMG_0347.txt',\n",
       " 'IMG_0390.txt',\n",
       " 'IMG_20230213_170532.txt',\n",
       " 'IMG_20230213_170534.txt',\n",
       " 'IMG_20230213_170536.txt',\n",
       " 'IMG_20230213_170540.txt',\n",
       " 'IMG_20230213_170543.txt',\n",
       " 'IMG_20230213_170545.txt',\n",
       " 'IMG_20230213_170546.txt',\n",
       " 'IMG_20230213_170549.txt',\n",
       " 'IMG_20230213_170551.txt',\n",
       " 'IMG_20230213_170553.txt',\n",
       " 'IMG_20230213_170557.txt',\n",
       " 'IMG_20230213_170601.txt',\n",
       " 'IMG_20230213_170602.txt',\n",
       " 'IMG_20230213_170606.txt',\n",
       " 'IMG_20230213_170607.txt',\n",
       " 'IMG_20230213_170608.txt',\n",
       " 'IMG_20230213_170610.txt',\n",
       " 'IMG_20230213_170611.txt',\n",
       " 'IMG_20230213_170612.txt',\n",
       " 'IMG_20230213_170614.txt',\n",
       " 'IMG_20230213_170615.txt',\n",
       " 'IMG_20230213_170616.txt',\n",
       " 'IMG_20230213_170618.txt',\n",
       " 'IMG_20230213_170619.txt',\n",
       " 'IMG_20230213_170620.txt',\n",
       " 'IMG_20230213_170621.txt',\n",
       " 'IMG_20230213_170622.txt',\n",
       " 'IMG_20230213_170623.txt',\n",
       " 'IMG_20230213_170624.txt',\n",
       " 'IMG_20230213_170624__01.txt',\n",
       " 'IMG_20230213_170625.txt',\n",
       " 'IMG_20230213_170626.txt',\n",
       " 'IMG_20230213_170627.txt',\n",
       " 'IMG_20230213_170628.txt',\n",
       " 'IMG_20230213_170630.txt',\n",
       " 'IMG_20230213_170632.txt',\n",
       " 'IMG_20230213_170634.txt',\n",
       " 'IMG_20230213_170636.txt',\n",
       " 'IMG_20230213_170637.txt',\n",
       " 'IMG_20230213_170640.txt',\n",
       " 'IMG_20230213_170642.txt',\n",
       " 'IMG_20230213_170643.txt',\n",
       " 'IMG_20230213_170643__01.txt',\n",
       " 'IMG_20230213_170645.txt',\n",
       " 'IMG_20230213_170647.txt',\n",
       " 'IMG_20230213_170651.txt',\n",
       " 'IMG_20230213_170652.txt',\n",
       " 'IMG_20230213_170653.txt',\n",
       " 'IMG_20230213_170656.txt',\n",
       " 'IMG_20230213_170657.txt',\n",
       " 'IMG_20230213_170821.txt',\n",
       " 'IMG_20230213_170822.txt',\n",
       " 'IMG_20230213_170824.txt',\n",
       " 'IMG_20230213_170826.txt',\n",
       " 'IMG_20230213_170837.txt',\n",
       " 'IMG_20230213_170839.txt',\n",
       " 'IMG_20230213_170841.txt',\n",
       " 'IMG_20230213_170843.txt',\n",
       " 'IMG_20230213_170846.txt',\n",
       " 'IMG_20230213_170847.txt',\n",
       " 'IMG_20230213_170849.txt',\n",
       " 'IMG_20230213_170916.txt',\n",
       " 'IMG_20230213_170921.txt',\n",
       " 'IMG_20230213_170922.txt',\n",
       " 'IMG_20230213_170923.txt',\n",
       " 'IMG_20230213_170924.txt',\n",
       " 'IMG_20230213_170925.txt',\n",
       " 'IMG_20230213_170927.txt',\n",
       " 'IMG_20230213_170928.txt',\n",
       " 'IMG_20230213_170929.txt',\n",
       " 'IMG_20230213_170930.txt',\n",
       " 'IMG_20230213_170932.txt',\n",
       " 'IMG_9559.txt',\n",
       " 'IMG_9560.txt',\n",
       " 'IMG_9655.txt',\n",
       " 'IMG_9669.txt',\n",
       " 'pexels-pixabay-268533.txt']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IMG_0345.JPG',\n",
       " 'IMG_0347.JPG',\n",
       " 'IMG_0390.JPG',\n",
       " 'IMG_20230213_170532.jpg',\n",
       " 'IMG_20230213_170534.jpg',\n",
       " 'IMG_20230213_170536.jpg',\n",
       " 'IMG_20230213_170540.jpg',\n",
       " 'IMG_20230213_170543.jpg',\n",
       " 'IMG_20230213_170545.jpg',\n",
       " 'IMG_20230213_170546.jpg',\n",
       " 'IMG_20230213_170549.jpg',\n",
       " 'IMG_20230213_170551.jpg',\n",
       " 'IMG_20230213_170553.jpg',\n",
       " 'IMG_20230213_170557.jpg',\n",
       " 'IMG_20230213_170601.jpg',\n",
       " 'IMG_20230213_170602.jpg',\n",
       " 'IMG_20230213_170606.jpg',\n",
       " 'IMG_20230213_170607.jpg',\n",
       " 'IMG_20230213_170608.jpg',\n",
       " 'IMG_20230213_170610.jpg',\n",
       " 'IMG_20230213_170611.jpg',\n",
       " 'IMG_20230213_170612.jpg',\n",
       " 'IMG_20230213_170614.jpg',\n",
       " 'IMG_20230213_170615.jpg',\n",
       " 'IMG_20230213_170616.jpg',\n",
       " 'IMG_20230213_170618.jpg',\n",
       " 'IMG_20230213_170619.jpg',\n",
       " 'IMG_20230213_170620.jpg',\n",
       " 'IMG_20230213_170621.jpg',\n",
       " 'IMG_20230213_170622.jpg',\n",
       " 'IMG_20230213_170623.jpg',\n",
       " 'IMG_20230213_170624.jpg',\n",
       " 'IMG_20230213_170624__01.jpg',\n",
       " 'IMG_20230213_170625.jpg',\n",
       " 'IMG_20230213_170626.jpg',\n",
       " 'IMG_20230213_170627.jpg',\n",
       " 'IMG_20230213_170628.jpg',\n",
       " 'IMG_20230213_170630.jpg',\n",
       " 'IMG_20230213_170632.jpg',\n",
       " 'IMG_20230213_170634.jpg',\n",
       " 'IMG_20230213_170636.jpg',\n",
       " 'IMG_20230213_170637.jpg',\n",
       " 'IMG_20230213_170640.jpg',\n",
       " 'IMG_20230213_170642.jpg',\n",
       " 'IMG_20230213_170643.jpg',\n",
       " 'IMG_20230213_170643__01.jpg',\n",
       " 'IMG_20230213_170645.jpg',\n",
       " 'IMG_20230213_170647.jpg',\n",
       " 'IMG_20230213_170651.jpg',\n",
       " 'IMG_20230213_170652.jpg',\n",
       " 'IMG_20230213_170653.jpg',\n",
       " 'IMG_20230213_170656.jpg',\n",
       " 'IMG_20230213_170657.jpg',\n",
       " 'IMG_20230213_170821.jpg',\n",
       " 'IMG_20230213_170822.jpg',\n",
       " 'IMG_20230213_170824.jpg',\n",
       " 'IMG_20230213_170826.jpg',\n",
       " 'IMG_20230213_170837.jpg',\n",
       " 'IMG_20230213_170839.jpg',\n",
       " 'IMG_20230213_170841.jpg',\n",
       " 'IMG_20230213_170843.jpg',\n",
       " 'IMG_20230213_170846.jpg',\n",
       " 'IMG_20230213_170847.jpg',\n",
       " 'IMG_20230213_170849.jpg',\n",
       " 'IMG_20230213_170916.jpg',\n",
       " 'IMG_20230213_170921.jpg',\n",
       " 'IMG_20230213_170922.jpg',\n",
       " 'IMG_20230213_170923.jpg',\n",
       " 'IMG_20230213_170924.jpg',\n",
       " 'IMG_20230213_170925.jpg',\n",
       " 'IMG_20230213_170927.jpg',\n",
       " 'IMG_20230213_170928.jpg',\n",
       " 'IMG_20230213_170929.jpg',\n",
       " 'IMG_20230213_170930.jpg',\n",
       " 'IMG_20230213_170932.jpg',\n",
       " 'IMG_9559.JPG',\n",
       " 'IMG_9560.JPG',\n",
       " 'IMG_9655.JPG',\n",
       " 'IMG_9669.JPG',\n",
       " 'pexels-pixabay-268533.jpg']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in labels:\n",
    "    #print(f\"C:/Users/nites/Documents/data_science/computer_vision/my_photo/nitesh/{i}\")\n",
    "    source=f\"C:/Users/nites/Documents/data_science/computer_vision/my_photo/nitesh/{i}\"\n",
    "    base_path=\"C:/Users/nites/Documents/data_science/computer_vision/my_photo/labels/\"\n",
    "    destination=os.path.join(base_path,i)\n",
    "    #print(destination)\n",
    "    shutil.copy(source,destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in images:\n",
    "    source=f\"C:/Users/nites/Documents/data_science/computer_vision/my_photo/nitesh/{i}\"\n",
    "    base_path=\"C:/Users/nites/Documents/data_science/computer_vision/my_photo/images/\"\n",
    "    destination=os.path.join(base_path,i)\n",
    "    #print(destination)\n",
    "    shutil.copy(source,destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensrflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "034baf3aa3fa971fbcd139e2abc9d6306158605465fc9f57b28b46c4f0938ce5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
